{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27a47a7-54ad-4866-b16c-90933a17a9f2",
   "metadata": {
    "name": "Title",
    "collapsed": false
   },
   "source": "# Multiclass Defect Detection with Distributed training using PyTorch Object Detection Models in Snowflake Notebooks\n"
  },
  {
   "cell_type": "code",
   "id": "dc94dc00-422d-423d-bf6c-cbfe8ef7a175",
   "metadata": {
    "language": "python",
    "name": "headers",
    "collapsed": false
   },
   "outputs": [],
   "source": "!pip freeze | grep snow\n!pip install opencv-python-headless\n\nimport torch\nimport torchvision\nprint(torch.__version__)\nprint(torchvision.__version__)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c99c1be8-b51c-44b5-b769-5f7fcd16feb1",
   "metadata": {
    "name": "mk1",
    "collapsed": false
   },
   "source": "## Install necessary packages:\n\n* torch\n* torchvision\n* opencv\n* matplotlib\n* Pillow"
  },
  {
   "cell_type": "code",
   "id": "c8c23e35-93ed-4665-afb2-4614e504827c",
   "metadata": {
    "language": "python",
    "name": "installcv",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "!pip install opencv-python\n!apt update && apt install -y libsm6 libxext6\n!apt-get install -y libxrender-dev",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33097ff5-5bfe-49dd-a147-7e3b962919e6",
   "metadata": {
    "name": "mk2",
    "collapsed": false
   },
   "source": "### Import necessary packages"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "Importheader",
    "collapsed": false
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nfrom snowflake.snowpark.context import get_active_session\n\nimport os\nimport sys\nimport time\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as T\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\n\n\nimport numpy as np\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nfrom snowflake.ml.registry import Registry\n\nfrom snowflake.snowpark import functions as F\nfrom snowflake.snowpark import types as T\n\nfrom snowflake.ml.modeling.distributors.pytorch import PyTorchDistributor, PyTorchScalingConfig, WorkerResourceConfig\nfrom snowflake.ml.data.sharded_data_connector import DataConnector, ShardedDataConnector\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "de9a9b6a-bdd6-40d5-bcb8-d101ed04df44",
   "metadata": {
    "language": "python",
    "name": "devices",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Get device info\nif torch.cuda.is_available():\n    num_gpus = torch.cuda.device_count()\n    print(\"Number of GPU devices available:\", num_gpus)\n    \n    for i in range(num_gpus):\n        print(\"Device\", i, \":\", torch.cuda.get_device_name(i))\n    \n    #Set a default device\n    torch.cuda.set_device(0)\nelse:\n    print(\"CUDA is not available. Check your installation or GPU setup.\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "250bed13-6cfd-4ff5-bb59-84894d62c9c2",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "### View the training dataset"
  },
  {
   "cell_type": "code",
   "id": "6c84721d-d9ba-44ed-b5db-db91fd69c382",
   "metadata": {
    "language": "python",
    "name": "Dataset_sample",
    "collapsed": false
   },
   "outputs": [],
   "source": "session.table(\"training_data\").limit(5).collect();",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9afef197-07d0-41b5-b485-7f5fd32a0a63",
   "metadata": {
    "name": "Train_heading",
    "collapsed": false
   },
   "source": "# Training\n\n## Step 1: Define a Training Function for Each Worker\n\nCreate a function that defines the training process for an individual worker. This function will be executed independently on each worker during distributed training.\n\n## Step 2: Execute the Training Function Using PyTorchDistributor\n\nUse the PyTorchDistributor to distribute and manage the execution of the training function across multiple workers.\n\n* The **ShardedDataConnector** ensures that the dataset is evenly partitioned (sharded) and distributed across all workers.\n* The **PyTorchScalingConfig** specifies the number of workers and necessary resources (e.g., CPUs, GPUs, memory) for each worker.\n"
  },
  {
   "cell_type": "code",
   "id": "8883e4b4-8058-4b36-82c1-cfde8ef54a26",
   "metadata": {
    "language": "python",
    "name": "Train_function",
    "collapsed": false
   },
   "outputs": [],
   "source": "import base64\nimport io\nimport cv2\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader, IterableDataset\nfrom PIL import Image\nimport torchvision\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn  \nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor  \nfrom torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights \nimport torch.distributed as dist\nfrom snowflake.ml.modeling.distributors.pytorch import get_context\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport tempfile\nimport cloudpickle as cp\n\ndef train_func():\n    context = get_context()\n    rank = context.get_rank()\n    dist.init_process_group(backend=\"nccl\")\n    print(f\"Worker Rank : {rank}, world_size: {context.get_world_size()}\")\n\n    ###\n    #  Wrapper to transform the dataset.\n    ###\n    class FCBData(IterableDataset):\n        def __init__(self, source_dataset, transforms=None):  \n            self.source_dataset = source_dataset\n            self.transforms = transforms if transforms else torchvision.transforms.ToTensor()  # Ensure we apply ToTensor transform\n    \n        def __iter__(self):\n            for row in self.source_dataset:\n                base64_image = row['IMAGE_DATA']\n                image = Image.open(io.BytesIO(base64.b64decode(base64_image)))\n                # Convert the image to a tensor\n                image = self.transforms(image)  # Converts PIL image to tensor\n    \n                # Extract bounding box and labels\n                boxes = [[row[k].item() for k in [\"XMIN\", \"YMIN\", \"XMAX\", \"YMAX\"]] for _ in range(1)]\n                labels = [row[\"CLASS\"].item()]\n    \n                boxes = torch.as_tensor(boxes, dtype=torch.float32)  \n                labels = torch.as_tensor(labels, dtype=torch.int64)\n                \n                # Prepare the target dictionary\n                target = {  \n                    'boxes': boxes,  \n                    'labels': labels,  \n                    'image_id': torch.tensor([int(row[\"FILENAME\"])]),\n                    'area': (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1]),  # Calculate area\n                    'iscrowd': torch.zeros((boxes.shape[0],), dtype=torch.uint8)  # Set iscrowd to 0 for all\n                }\n                yield (image, target)\n\n    with torch.cuda.device(rank):\n        # Model initialization\n        weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT  \n        model = fasterrcnn_resnet50_fpn(weights=weights)\n          \n        # Modify the model for your number of classes (including background)\n        num_classes = 6  \n        in_features = model.roi_heads.box_predictor.cls_score.in_features  \n        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n        model.to(rank)\n        model = DDP(model, device_ids=[rank])\n        \n    \n        optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.0001, weight_decay=0.0005)\n        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n    \n        # Load the data using ShardedDataConnector\n        dataset_map = context.get_dataset_map()\n        train_shard = dataset_map[\"train\"].get_shard().to_torch_dataset()\n        train_dataset = FCBData(train_shard)\n    \n        # get hyper_params \n        hyper_parms = context.get_hyper_params()\n        \n        def collate_fn(batch):\n            return tuple(zip(*batch))\n    \n        batch_size = int(hyper_parms['batch_size'])\n        train_data_loader = DataLoader(\n            train_dataset,\n            batch_size=batch_size,\n            shuffle=False,\n            collate_fn=collate_fn,\n            pin_memory=True,\n            pin_memory_device=f\"cuda:{rank}\"\n        )\n\n        # Training loop\n        num_epochs = int(hyper_parms['num_epochs'])\n        for epoch in range(num_epochs):\n            model.train()\n            running_loss = 0.0\n            running_batches = 0\n            for images, targets in train_data_loader:\n                running_batches = running_batches + 1\n                images = [image.float() / 255.0 for image in images]\n                images = [image.to(rank) for image in images]\n                targets = [{k: v.to(rank) for k, v in t.items()} for t in targets]\n                \n                loss_dict = model(images, targets)\n                losses = sum(loss for loss in loss_dict.values())\n                \n                optimizer.zero_grad()\n                losses.backward()\n                optimizer.step()\n    \n                running_loss += losses.item()\n    \n            print(f\"[Rank {rank}] Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / (running_batches*batch_size):.4f}, Processed {running_batches * (epoch+1) * batch_size} images so far\")\n            lr_scheduler.step()\n    \n        MODEL_PATH = \"/tmp/models/detectionmodel.pt\"\n        if rank == 0:\n            with open(MODEL_PATH, mode=\"w+b\") as model_file:\n                    torch.save(model.module.state_dict(), model_file)\n            print(f\"Model written to {MODEL_PATH}\")\n    \n        print(f\"[Rank {rank}] Training completed.\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14a83929-ea61-4d1d-98a0-13637768a4dd",
   "metadata": {
    "name": "traindataset",
    "collapsed": false
   },
   "source": "### For the purpose of this quickstart, we have considered a smaller volume as the data source. But ideally this can scale million rows\n\n1. Split the dataset (shard) for distributed training across multiple workers.\n2. Train a PyTorch model using 4 workers, each utilizing 1 GPU for efficient computation. Control the training with hyperparameters such as batch size and number of epochs."
  },
  {
   "cell_type": "code",
   "id": "d37e1ca6-34ac-47b2-9e3a-8295712a99b5",
   "metadata": {
    "language": "python",
    "name": "Train_dataset",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Set up PyTorchDistributor\nfrom snowflake.ml.modeling.distributors.pytorch import PyTorchDistributor, PyTorchScalingConfig, WorkerResourceConfig  \nfrom snowflake.ml.data.sharded_data_connector import ShardedDataConnector  \n\ndf = session.table(\"training_data\")\n\n# Create sharded data connector.\ntrain_data = ShardedDataConnector.from_dataframe(df)\n\n# Create pytorch distributor.\npytorch_trainer = PyTorchDistributor(  \n    train_func=train_func,\n    scaling_config=PyTorchScalingConfig(  \n        num_nodes=1,  \n        num_workers_per_node=4,  \n        resource_requirements_per_worker=WorkerResourceConfig(num_cpus=0, num_gpus=1),  \n    )  \n)  \n\n# Run the trainer.\npytorch_trainer.run(\n    dataset_map={\"train\": train_data},\n    hyper_params={\"batch_size\": \"32\", \"num_epochs\": \"5\"}\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a907a9df-75d9-4b1e-b65d-d7cd08b51c70",
   "metadata": {
    "name": "modeldeploy",
    "collapsed": false
   },
   "source": "# MODEL DEPLOYMENT\n"
  },
  {
   "cell_type": "markdown",
   "id": "465650d2-213f-4dc1-ab29-39d8915d1756",
   "metadata": {
    "name": "modelreg",
    "collapsed": false
   },
   "source": "# Snowflake Model Registry - Securely manage models and their metadata in Snowflake.\n\nThe model registry stores machine learning models as first-class schema-level objects in Snowflake.\n\n* Load the model produced by trainer \n* Define custom wrapper for the PyTorch model\n* Save it to Model Registry by specifying the model_name,version_name,input dataframe as signature and conda_dependencies"
  },
  {
   "cell_type": "code",
   "id": "9ca0a785-ed92-4363-a6e2-bfbcc057adfb",
   "metadata": {
    "language": "python",
    "name": "logmodeltoregistry_customwrapper",
    "collapsed": false
   },
   "outputs": [],
   "source": "import torch\nimport torchvision.transforms as transforms\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_Weights\nfrom PIL import Image\nimport io\nimport json\nimport base64\ndf=session.table(\"VAL_IMAGES_LABELS\").limit(1).to_pandas()\n\nfirst_row = df.iloc[0]  \nbase64_image = first_row['IMAGE_DATA'] \ndf = pd.DataFrame({'IMAGE_DATA': [base64_image]})  \n\nspdf=session.create_dataframe(df)\n# Function to load the model\ndef load_model(model_path):  \n    weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT  \n    model = fasterrcnn_resnet50_fpn(weights=weights)  \n    \n    # Modify the box predictor for your specific dataset\n    num_classes = 6  # Background + 5 classes\n    in_features = model.roi_heads.box_predictor.cls_score.in_features  \n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)  \n    model.load_state_dict(torch.load(model_path), strict=False)  \n    model.double()\n    model.eval()  \n    return model  \n\n# Function to decode and transform an image\ndef decode_and_transform_image(base64_image):  \n    image_data = base64.b64decode(base64_image)  \n    image = Image.open(io.BytesIO(image_data)).convert('RGB')  \n    if image.mode != 'RGB':\n        image = image.convert('RGB')\n    # Define the necessary transformations\n    transform = transforms.Compose([  \n        transforms.Resize((224, 224)), \n        transforms.ToTensor(),  # Converts to [C, H, W]\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n    ])  \n    image_tensor = transform(image)\n    image_tensor = image_tensor.double()\n    \n    # Debugging: Print the shape after transformation\n    print(f\"Shape after transformation: {image_tensor.shape}\")\n    \n    return image_tensor\n\n\n# try:\nmodel_path = '/tmp/models/detectionmodel.pt'\nmodel = load_model(model_path)\n\nfrom snowflake.ml.model import custom_model\n\nclass DefectDetectionModel(custom_model.CustomModel):\n    def __init__(self, context: custom_model.ModelContext) -> None:\n        super().__init__(context)\n\n    @custom_model.inference_api\n    def predict(self, input_df: pd.DataFrame) -> pd.DataFrame:\n        processed_input = torch.stack(input_df['IMAGE_DATA'].apply(decode_and_transform_image).to_list())\n        raw_output = self.context.model_ref(\"rcnn\").forward(processed_input)\n        final_output = pd.DataFrame({\"output\": [json.dumps({k: v.detach().cpu().numpy().tolist() for k, v in res.items()}) for res in raw_output]})\n        return final_output\n\nddm = DefectDetectionModel(context = custom_model.ModelContext(models={'rcnn': model}))\n\n\nml_reg = Registry(session=session)  \n# Log the model with the sample input for Snowflake registry\nmv = ml_reg.log_model(  \n    ddm,  \n    model_name=\"DefectDetectionModel\",  \n    version_name='v3',  \n    sample_input_data=spdf,\n    conda_dependencies=[\"pytorch\", \"torchvision\"],\n    options={\"embed_local_ml_library\": True,\n             \n                \"relax\": True}\n\n)\n    ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "240369f3-e766-453f-acbe-245c8d0a444f",
   "metadata": {
    "name": "mk3",
    "collapsed": false
   },
   "source": "## Fetch the logged Model from Snowflake Registry\n\n"
  },
  {
   "cell_type": "code",
   "id": "d9d32ac1-da76-4f35-be25-46fd63747aee",
   "metadata": {
    "language": "python",
    "name": "registry_init",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Usage Example\nreg = Registry(session=session) \nmodel_ref = reg.show_models()\nmodel_ref",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bbb44e09-e1e1-42f5-9792-9a070713a310",
   "metadata": {
    "name": "mk4",
    "collapsed": false
   },
   "source": "## Detect Defects on Validation dataset\nLets consider there is a validation table VAL_IMAGES_LABELS which contains the Base64 Encoding information of validation images.\n\n* Get a reference to a specific model from the registry by name using the registry’s get_model method\n* Get a reference to a specific version of a model as a ModelVersion instance using the model’s version method.\n* Carry inference using the model and output the predictions\n"
  },
  {
   "cell_type": "code",
   "id": "d4235d30-0724-4d7b-875b-b7403fe933c3",
   "metadata": {
    "language": "python",
    "name": "perform_inference",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nm = reg.get_model(\"DEFECTDETECTIONMODEL\")\nmv = m.version(\"GENTLE_DONKEY_4\")\n\n\ndf=session.table(\"VAL_IMAGES_LABELS\").limit(1).to_pandas()\n\nfirst_row = df.iloc[0]\nbase64_image = first_row['IMAGE_DATA'] \nimage_data_df = pd.DataFrame({'IMAGE_DATA': [base64_image]})  \nimage_data_df.head()\n\n\n\nremote_prediction = mv.run(image_data_df, function_name=\"predict\")\nremote_prediction.head()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1171d107-c228-4d7b-8cbb-d92469c83c69",
   "metadata": {
    "name": "displayimage",
    "collapsed": false
   },
   "source": "Fetch predictions and use a function display_image_with_boxes() to display Image with Bounding Boxes and Labels\n"
  },
  {
   "cell_type": "code",
   "id": "d92228f7-74bc-45fc-8c18-c8db544f919b",
   "metadata": {
    "language": "python",
    "name": "visualize_defects",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import json\nimport base64\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\nimport io\n\n# Class mapping dictionary\nclasses_la = {\n    0: \"open\",\n    1: \"short\",\n    2: \"mousebite\",\n    3: \"spur\",\n    4: \"copper\",\n    5: \"pin-hole\"\n}\n\n# Function to display the image with bounding boxes and class labels\ndef display_image_with_boxes(image, boxes, labels, scores, target_size=(800, 600)):\n    # Resize the image to a target size\n    img = image.resize(target_size).convert(\"RGB\")  # Resize and convert to RGB\n    img_np = np.array(img)\n\n    # Adjust the DPI and figure size\n    fig, ax = plt.subplots(figsize=(3, 6), dpi=10)  # Adjust figure size and DPI\n    ax.imshow(img_np)\n\n    for label, box, score in zip(labels, boxes, scores):\n        xmin, ymin, xmax, ymax = box\n        class_label = classes_la[label]\n\n        # Create a Rectangle patch\n        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n        ax.text(xmin, ymin, f\"{class_label}: {score:.2f}\", verticalalignment='top', color='red', fontsize=13, weight='bold')\n        ax.add_patch(rect)\n\n    plt.axis('off')\n    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Ensure no padding/margins around the image\n    plt.show()\n\n# Combine the image data and remote prediction DataFrames\ncombined_df = pd.concat([image_data_df, remote_prediction], axis=1)\n\n# Create a list to store data for the final DataFrame\nrows = []\n\n# Iterate through each row in the combined DataFrame\nfor index, row in combined_df.iterrows():\n    output_str = row.get('output', None)  # Get the output column value\n\n    if isinstance(output_str, str):  # Ensure it's a valid string before loading as JSON\n        try:\n            # Convert the 'output' column JSON string into a dictionary\n            output_data = json.loads(output_str)\n\n            # Extract boxes, labels, and scores from JSON data\n            if 'boxes' in output_data and 'labels' in output_data and 'scores' in output_data:\n                boxes = output_data['boxes']\n                labels = output_data['labels']\n                scores = output_data['scores']\n\n                # Decode the image data\n                image_data = base64.b64decode(row['IMAGE_DATA'])\n                image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n\n                # Limit to top 5 classes based on scores\n                if len(scores) > 0:\n                    # Create a DataFrame to manage boxes, labels, and scores\n                    data = pd.DataFrame({\n                        'box': boxes,\n                        'label': labels,\n                        'score': scores\n                    })\n\n                    # Get the top 5 entries based on scores\n                    top_classes = data.nlargest(5, 'score')\n\n                    # Extract corresponding boxes, labels, and scores\n                    top_boxes = top_classes['box'].tolist()\n                    top_labels = top_classes['label'].tolist()\n                    top_scores = top_classes['score'].tolist()\n\n                    # Store each of the top 5 predictions as a separate row\n                    for i in range(len(top_boxes)):\n                        rows.append({\n                            'image_data': row['IMAGE_DATA'],\n                            'output': row['output'],\n                            'label': top_labels[i],\n                            'box': top_boxes[i],\n                            'score': top_scores[i]\n                        })\n\n                    # Display the image with bounding boxes and labels\n                    display_image_with_boxes(image, top_boxes, top_labels, top_scores)\n                else:\n                    print(\"No scores available to limit to top 5.\")\n            else:\n                print(\"Missing keys 'boxes', 'labels', or 'scores' in the output data.\")\n\n        except json.JSONDecodeError:\n            print(f\"Invalid JSON in row {index}, skipping this row.\")\n    else:\n        print(f\"Invalid output type (not a string) in row {index}, skipping this row.\")\n\n# Create the final DataFrame with the collected rows (one row per label/box/score)\nfinal_df = pd.DataFrame(rows)\nsession.sql(\"create TABLE if not exists PCB_DATASET.PUBLIC.DETECTION_OUTPUTS (\n\timage_data VARCHAR(16777216),\n\toutput VARCHAR(16777216),\n\tlabel NUMBER(38,0),\n\tbox VARIANT,\n\tscore FLOAT\n)\").collect()\n\n# Write the DataFrame to the Snowflake table\ncombined_spdf = session.create_dataframe(final_df)\ncombined_spdf.write.save_as_table(\"DETECTION_OUTPUTS\", mode=\"overwrite\")\n",
   "execution_count": null
  }
 ]
}